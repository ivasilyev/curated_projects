{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from meta.scripts.Utilities import Utilities\n",
    "from meta.scripts.sample_data import SampleDataArray\n",
    "from ashestopalov.nutrition.obesity_metagenomes.ProjectDescriber import ProjectDescriber\n",
    "\n",
    "_ = \"\"\"\n",
    "\n",
    "\n",
    "To access a JupyterLabserver on http://ip_address:61156/?token=TOKEN:\n",
    "export IMG=ivasilyev/curated_projects:latest && \\\n",
    "docker pull ${IMG} && \\\n",
    "docker run --rm -v /data:/data -v /data1:/data1 -v /data2:/data2 --net=host -it ${IMG} bash\n",
    "\n",
    "git pull && jupyter lab --ip=0.0.0.0 --port=61156 --no-browser --NotebookApp.token=TOKEN\n",
    "\"\"\"\n",
    "\n",
    "DIRS = \"\"\"191023_M01969_0092_000000000-CMKKY\n",
    "191111_M05780_0056_000000000-CMJRN\n",
    "191122_M04046_0124_000000000-CMKPP\n",
    "191203_M04046_0129_000000000-CMJR5\n",
    "191223_M04046_0130_000000000-CMMM7\n",
    "200211_M04046_0132_000000000-CMKFR\n",
    "\"\"\"\n",
    "\n",
    "SAMPLE_SOURCES = (\"blood\", \"stool\")\n",
    "MAX_SAMPLE_BATCH_SIZE = 10  # Save RAM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "source_raw_reads_files = {i: [] for i in SAMPLE_SOURCES}\n",
    "for dir_base_name in Utilities.split_lines(DIRS):\n",
    "    dir_name = os.path.join(\"/data1/bio/\", dir_base_name)\n",
    "    conversion_dirs = [j for j in [os.path.join(dir_name, i) for i in list(os.listdir(dir_name)) \n",
    "                                   if \"conversion\" in os.path.basename(i).lower()] \n",
    "                       if os.path.isdir(j)]\n",
    "    for conversion_dir in conversion_dirs:\n",
    "        project_dirs = [j for j in [os.path.join(conversion_dir, i) for i in list(os.listdir(\n",
    "            conversion_dir)) if \"rogachev\" in os.path.basename(i).lower()] if os.path.isdir(j)]\n",
    "        if len(project_dirs) == 0:\n",
    "            continue\n",
    "        for project_dir in project_dirs:\n",
    "            for sample_source in SAMPLE_SOURCES:\n",
    "                if sample_source in os.path.basename(project_dir).lower():\n",
    "                    raw_reads_files_by_sample_source = [i for i in Utilities.scan_whole_dir(\n",
    "                        project_dir) if os.path.isfile(i) and not os.path.islink(i) and any(\n",
    "                        i.endswith(j) for j in [\".fq.gz\", \".fastq.gz\"])]\n",
    "                    source_raw_reads_files[sample_source].extend(raw_reads_files_by_sample_source)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "target_raw_reads_files = {i: [] for i in SAMPLE_SOURCES}\n",
    "existing_raw_reads_files = []\n",
    "source_raw_reads_data = []\n",
    "for sample_source in SAMPLE_SOURCES:\n",
    "    target_raw_reads_dir = os.path.join(ProjectDescriber.RAW_READS_DIR, sample_source)\n",
    "    for source_raw_reads_file in source_raw_reads_files[sample_source]:\n",
    "        sample_name = Utilities.safe_findall(\"(.+)_S[0-9]+\", os.path.basename(source_raw_reads_file))\n",
    "        launch_date = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(\n",
    "            source_raw_reads_file)))).split(\"_\")[0]\n",
    "        target_raw_reads_file = os.path.join(target_raw_reads_dir, \"{}__{}\".format(\n",
    "            launch_date, os.path.basename(source_raw_reads_file)))\n",
    "        os.makedirs(os.path.dirname(target_raw_reads_file), exist_ok=True)\n",
    "        if os.path.isfile(target_raw_reads_file):\n",
    "            existing_raw_reads_files.append(target_raw_reads_file)\n",
    "        else:\n",
    "            shutil.copy2(source_raw_reads_file, target_raw_reads_file)\n",
    "        if target_raw_reads_file not in target_raw_reads_files[sample_source]:\n",
    "            target_raw_reads_files[sample_source].append(target_raw_reads_file)\n",
    "        source_raw_reads_data.append(dict(file_path=source_raw_reads_file, sample_name=sample_name, \n",
    "                                          file_size=os.path.getsize(source_raw_reads_file),\n",
    "                                          file_change_date=datetime.datetime.fromtimestamp(\n",
    "                                              os.stat(source_raw_reads_file).st_mtime), \n",
    "                                          target_name=os.path.basename(target_raw_reads_file),\n",
    "                                          target_alias=Utilities.safe_findall(\"(.+)_S[0-9]+_\",\n",
    "                                              os.path.basename(target_raw_reads_file))))\n",
    "\n",
    "Utilities.dump_tsv(pd.DataFrame(source_raw_reads_data), \n",
    "                   os.path.join(ProjectDescriber.SAMPLE_DATA_DIR, \"source_raw_reads_data.tsv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Duplicate sample data line key, the regex check is considered: '191223__166b'\n",
      "Duplicate sample data line key, the regex check is considered: '191223__057'\n",
      "Duplicate sample data line key, the regex check is considered: '191223__058'\n",
      "Duplicate sample data line key, the regex check is considered: '191223__061'\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sampledata_arrays = {i: SampleDataArray.generate(Utilities.split_list_by_chunk_length(sorted(\n",
    "    target_raw_reads_files[i]), 2), regex=\"(.+)_S[0-9]+_\") for i in SAMPLE_SOURCES}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "_ = [[sampledata_arrays[i].validate(), sampledata_arrays[i].update_lines_state(dict(\n",
    "    sample_source=i))] for i in SAMPLE_SOURCES]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Check if all the sample lines were parsed successfully\n",
    "assert sum([len(i) for i in target_raw_reads_files.values()]) == sum(\n",
    "    [len(i) for i in sampledata_arrays.values()] * 2)\n",
    "\n",
    "# Check if all the sample lines have 2 reads files\n",
    "assert len(Utilities.remove_empty_values([[j.name for j in i.lines.values() if len(j.reads) != 2 ] \n",
    "                                          for i in sampledata_arrays.values()])) == 0\n",
    "\n",
    "# Check if all the keys are unique (even if it's redundant)\n",
    "assert len(np.intersect1d(*[sampledata_arrays[i].export().keys() for i in sampledata_arrays])) == 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "chopped_sampledata_dir = os.path.join(ProjectDescriber.SAMPLE_DATA_DIR, \"chopped\")\n",
    "os.makedirs(chopped_sampledata_dir, exist_ok=True)\n",
    "for sample_source in SAMPLE_SOURCES:\n",
    "    source_info_dicts = []\n",
    "    _ = \"categorical\"\n",
    "    metadata_dicts = [{\"#SampleID\": \"#q2:types\", \"BarcodeSequence\": _, \"LinkerPrimerSequence\": _, \n",
    "                       \"Description\": _, \"sample_source\": _}, ]\n",
    "    sample_source_lines = [sampledata_arrays[sample_source].lines[i] for i in sorted(\n",
    "        sampledata_arrays[sample_source].lines.keys())]\n",
    "    for idx, reads_direction in enumerate([\"forward\", \"reverse\"]):\n",
    "        source_info_dicts.extend([{\"sample-id\": i.name, \"absolute-filepath\": i.reads[idx], \n",
    "                                   \"direction\": reads_direction} for i in sample_source_lines])\n",
    "    metadata_dicts.extend([{\"#SampleID\": i.name, \"BarcodeSequence\": \"\", \"LinkerPrimerSequence\": \"\", \n",
    "                            \"Description\": i.name, \"sample_source\": sample_source} \n",
    "                           for i in sample_source_lines])\n",
    "    source_info_df = pd.DataFrame(source_info_dicts).sort_values(\"absolute-filepath\").reset_index(\n",
    "        drop=True)\n",
    "    metadata_df = pd.DataFrame(metadata_dicts)\n",
    "    # \n",
    "    sampledata_arrays[sample_source].dump(os.path.join(\n",
    "        ProjectDescriber.SAMPLE_DATA_DIR, \"main_sample_data_{}.json\".format(sample_source)))\n",
    "    source_info_df.to_csv(os.path.join(\n",
    "        ProjectDescriber.SAMPLE_DATA_DIR, \"qiime2_sample_data_{}.csv\".format(sample_source)), \n",
    "        header=True, index=False)    \n",
    "    Utilities.dump_tsv(metadata_df, os.path.join(ProjectDescriber.SAMPLE_DATA_DIR, \n",
    "                                                 \"qiime2_meta_data_{}.tsv\".format(sample_source)))\n",
    "    # \n",
    "    source_info_df_index_chunks = Utilities.split_list_by_chunk_length(\n",
    "        list(range(source_info_df.shape[0])), MAX_SAMPLE_BATCH_SIZE * 2)    \n",
    "    for idx, source_info_df_index_chunk in enumerate(source_info_df_index_chunks):\n",
    "        chopped_sampledata_dir = os.path.join(ProjectDescriber.SAMPLE_DATA_DIR, \"chopped\")\n",
    "        source_info_df.loc[source_info_df_index_chunk, :].to_csv(os.path.join(\n",
    "            chopped_sampledata_dir, \"qiime2_sample_data_{}_chunk_{}.csv\".format(sample_source, idx)), \n",
    "            header=True, index=False)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}