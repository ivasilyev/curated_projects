{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.stats import multitest\n",
    "from meta.scripts.Utilities import Utilities\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "SINGLE_COMPARISON_ALPHA = 0.05"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def sanitize_series(s: pd.Series):\n",
    "    return s.where(lambda x: x > 0).dropna().sort_values(ascending=False)\n",
    "\n",
    "def dict_list_to_dataframe(list_: list, key_column_name: str, value_column_name: str, \n",
    "                           sort: bool = False):\n",
    "    out = pd.DataFrame(list_).set_index(key_column_name).sort_index()\n",
    "    out.columns.name = \"values\"\n",
    "    if sort:\n",
    "        out.sort_values(value_column_name, ascending=False, inplace=True)\n",
    "    return out\n",
    "\n",
    "def get_prevalents_dict(two_dim_array: list, names: list):\n",
    "    out = dict(is_common_by_sum=False, is_common_by_median=False, prevalent_by_sum=names[\n",
    "        get_prevalent_list_number(two_dim_array, func=sum)], prevalent_by_median=names[\n",
    "        get_prevalent_list_number(two_dim_array, func=np.median)])\n",
    "    for func, key in zip([sum, np.median], [\"is_common_by_sum\", \"is_common_by_median\"]):\n",
    "        if all(i > 0 for i in map(func, two_dim_array)):\n",
    "            out[key] = True\n",
    "    return out\n",
    "\n",
    "def get_u_test_dict(two_dim_array: list):\n",
    "    p_value = 1\n",
    "    if sum(map(sum, two_dim_array)) > 0:\n",
    "        p_value = stats.mannwhitneyu(*two_dim_array).__getattribute__(\"pvalue\")\n",
    "    out = dict(\n",
    "        p_value=p_value, is_significant_for_single_comparison=p_value < SINGLE_COMPARISON_ALPHA)\n",
    "    return out\n",
    "\n",
    "def get_distances_dict(two_dim_array: list):\n",
    "    out = dict(bray_curtis_dissimilarity=distance.braycurtis(*two_dim_array), \n",
    "               manhattan_distance=distance.cityblock(*two_dim_array), \n",
    "               euclidean_distance=distance.euclidean(*two_dim_array))\n",
    "    return out\n",
    "\n",
    "def get_multi_test_df(pvals: list, names: list):\n",
    "    reject, pvals_corrected, alpha_sidak, alpha_bonf = multitest.multipletests(\n",
    "        pvals, alpha=SINGLE_COMPARISON_ALPHA, method=\"fdr_bh\")\n",
    "    out = pd.DataFrame([reject, pvals_corrected], index=(\"is_significant_for_multiple_comparison\", \"corrected_p_value\"), columns=names).rename_axis(index=\"multi_test\").transpose()\n",
    "    out[\"corrected_alpha_for_Sidak_method\"] = alpha_sidak\n",
    "    out[\"corrected_alpha_for_Bonferroni_method\"] = alpha_bonf\n",
    "    return out\n",
    "\n",
    "def pair_flat_list(list_: list):\n",
    "    list_ = set(list_)\n",
    "    out = []\n",
    "    for pair in sorted(product(list_, list_)):\n",
    "        append = sorted(set(pair))\n",
    "        if len(append) > 1 and append not in out:\n",
    "            out.append(append)\n",
    "    return out\n",
    "\n",
    "def get_prevalent_list_number(two_dim_array: list, func):\n",
    "    \"\"\"\n",
    "    :param two_dim_array: 2D array\n",
    "    :param func: Comparing function, e.g. sum() or numpy.median()\n",
    "    :return: Number (zero-based) of list with the prevalent result\n",
    "    \"\"\"\n",
    "    results = [func(i) for i in two_dim_array]\n",
    "    return results.index(max(results))\n",
    "\n",
    "def get_counter_df(list_: list):\n",
    "    out = pd.DataFrame(Counter(list_).most_common(), columns=[\"words\", \"occurrences\"]).set_index(\n",
    "        \"words\")\n",
    "    out[\"occurrences\"] = out[\"occurrences\"].astype(int)\n",
    "    return out\n",
    "\n",
    "def zfill_list(list_: list):\n",
    "    list_ = [str(i) for i in list_]\n",
    "    return [i.zfill(len(max(list_, key=len))) for i in list_]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "output_dir = \"/data1/bio/projects/tgrigoreva/stool_to_blood\"\n",
    "table_file = os.path.join(output_dir, \"stool_blood_paired_only.xlsx\")\n",
    "table_df = pd.read_excel(table_file, encoding=\"utf-8\")\n",
    "table_df = table_df.loc[:, list(filter(lambda x: len(x.strip()) > 0 and \"unnamed\" not in x.lower(), \n",
    "                                       table_df.columns))]\n",
    "table_df[\"patient_ages\"] = table_df[\"Диагноз\"].apply(lambda x: x.split(\"_\")[0])\n",
    "table_df[\"patient_diagnoses\"] = table_df[\"Диагноз\"].apply(lambda x: x.split(\"_\")[-1])\n",
    "taxonomy_columns = [i for i in table_df.columns if any(i.startswith(j) for j in (\"k_\", \"Unassigned\"))]\n",
    "\n",
    "table_df.loc[table_df[\"ID\"] == \"166b\", \"type\"] = \"blood\"\n",
    "table_df = table_df.replace({\"ЯК\": \"colitis\", \"здоровый\": \"normal\", \"ожирение\": \"obesity\", \n",
    "                             \"Ребенок\": \"child\", \"Взрослый\": \"adult\"}).rename(\n",
    "    columns={\"ID\": \"sample_names\", \"type\": \"sample_sources\", \"N_human\": \"patient_ids\"}).drop(\n",
    "    \"Диагноз\", axis=1)\n",
    "table_df[\"patient_ids\"] = zfill_list(table_df[\"patient_ids\"].values.tolist())\n",
    "table_index_levels = [\"sample_names\", \"sample_sources\", \"patient_ids\", \"patient_diagnoses\", \n",
    "                      \"patient_ages\"]\n",
    "table_df = table_df.set_index(table_index_levels).loc[:, taxonomy_columns].rename_axis(\n",
    "    columns=\"taxa\")\n",
    "table_ds = pd.melt(table_df.reset_index(), id_vars=table_index_levels, value_vars=taxonomy_columns, \n",
    "                   value_name=\"relative_abundances\")\n",
    "table_ds = table_ds.loc[table_ds[\"relative_abundances\"] > 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "table_sample_names, table_sample_sources, table_patient_ids, table_diagnoses, table_ages = [\n",
    "    sorted(set(table_df.index.get_level_values(i))) for i in table_index_levels]\n",
    "diagnosis_group_pairs = pair_flat_list(table_diagnoses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "class DataHolder:\n",
    "    \"\"\"\n",
    "    Holds per-group data\n",
    "    \"\"\"\n",
    "    def __init__(self, age: str, diagnosis: str, sample_source: str):\n",
    "        self.age = age\n",
    "        self.diagnosis = diagnosis\n",
    "        self.sample_source = sample_source\n",
    "        \n",
    "        self.raw_ds = table_ds.query(\n",
    "            \"patient_ages == '{}' and patient_diagnoses == '{}' and sample_sources == '{}'\".format(\n",
    "                self.age, self.diagnosis, self.sample_source))\n",
    "        self.common_taxonomy_counter_df = get_counter_df(self.raw_ds[\"taxa\"])\n",
    "        \n",
    "        # Payload for PCA plot\n",
    "        if self.sample_source.strip() == \"stool\":\n",
    "            self.edgecolors = \"blue\"\n",
    "        else:\n",
    "            self.edgecolors = \"red\"\n",
    "        if self.diagnosis.strip() == \"obesity\":\n",
    "            self.marker = \"s\"\n",
    "        elif diagnosis.strip() == \"colitis\":\n",
    "            self.marker = \"^\"\n",
    "        else:\n",
    "            self.marker = \"o\"\n",
    "        if self.age.strip() == \"child\":\n",
    "            self.facecolors = \"none\"\n",
    "        else:\n",
    "            self.facecolors = self.edgecolors\n",
    "\n",
    "        # More payload\n",
    "        self.taxonomy_df = self.raw_ds.pivot(\n",
    "            index=\"sample_names\", columns=\"taxa\", values=\"relative_abundances\").dropna(\n",
    "            axis=1, how=\"all\").fillna(0)\n",
    "        self.sample_names = sorted(set(self.taxonomy_df.index.values))\n",
    "        \n",
    "        self.mean_df = pd.DataFrame(sanitize_series(\n",
    "            self.taxonomy_df.mean(axis=0).rename(\"mean\"))).rename_axis(index=\"taxa\")\n",
    "        self.median_df = pd.DataFrame(sanitize_series(\n",
    "            self.taxonomy_df.median(axis=0).rename(\"median\"))).rename_axis(index=\"taxa\")\n",
    "        self.sum_df = pd.DataFrame(sanitize_series(\n",
    "            self.taxonomy_df.sum(axis=0).rename(\"sum\"))).rename_axis(index=\"taxa\")\n",
    "\n",
    "        self.out_dir = os.path.join(output_dir, \"single\", str(self))\n",
    "\n",
    "    @staticmethod\n",
    "    def series_to_df(series: pd.Series, key_column_name: str, value_column_name: str):\n",
    "        d = sanitize_series(series)\n",
    "        lst_ = [{key_column_name: k, value_column_name: d.get(k)} for k in d]\n",
    "        return dict_list_to_dataframe(lst_, key_column_name, value_column_name, sort=True)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"[{}]\".format(\", \".join([self.age, self.diagnosis, self.sample_source]))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<DataHolder({}) at {}, contains {} samples and {} taxa>\".format(\n",
    "            str(self), hex(id(self)), *self.taxonomy_df.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_names)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return str(self) < str(other)\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "      return other is not None and str(self) == str(other) \n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "    \n",
    "    def __hash__(self):\n",
    "      return hash(str(self))\n",
    "\n",
    "    def finalize_df(self, df: pd.DataFrame):\n",
    "        out_df = df.copy()\n",
    "        for col_name, value in zip([\"age\", \"diagnosis\", \"sample_source\"], \n",
    "                                   [self.age, self.diagnosis, self.sample_source]):\n",
    "            out_df[col_name] = value\n",
    "        return out_df\n",
    "    \n",
    "    def export(self):\n",
    "        out = {\"positive medians for {}.tsv\": self.median_df, \n",
    "               \"positive sums for {}.tsv\": self.sum_df,\n",
    "               \"pivot taxa for {}.tsv\": self.taxonomy_df,\n",
    "               \"melted per-sample taxa for {}.tsv\": self.raw_ds,\n",
    "               \"per-sample taxa counter for {}.tsv\": self.common_taxonomy_counter_df}\n",
    "        for k in out:\n",
    "            v = out.get(k)\n",
    "            if len(v.index.values) > 0:\n",
    "                Utilities.dump_tsv(v.reset_index(), os.path.join(self.out_dir, k.format(str(self))))\n",
    "\n",
    "\n",
    "data_holders = [DataHolder(*i) for i in list(\n",
    "    product(table_ages, table_diagnoses, table_sample_sources))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "whole_common_taxonomy_df = table_df.loc[:, table_ds[\"taxa\"]]\n",
    "whole_scaled_common_taxonomy_df = pd.DataFrame(\n",
    "    StandardScaler().fit_transform(whole_common_taxonomy_df), \n",
    "    columns=whole_common_taxonomy_df.columns, \n",
    "    index=whole_common_taxonomy_df.index.get_level_values(\"sample_names\"))\n",
    "whole_common_taxonomy_dir = os.path.join(output_dir, \"common\")\n",
    "\n",
    "_ = [Utilities.dump_tsv(i, os.path.join(whole_common_taxonomy_dir, j)) for i, j in zip(\n",
    "    [table_ds, whole_scaled_common_taxonomy_df.reset_index()], \n",
    "    [\"whole_dataset.tsv\", \"whole_scaled_common_taxonomy.tsv\"])]\n",
    "\n",
    "whole_common_pca_df = pd.DataFrame(PCA(n_components=2).fit_transform(\n",
    "    whole_scaled_common_taxonomy_df), columns=[\"PCA {}\".format(i) for i in range(1, 3)], \n",
    "    index=whole_scaled_common_taxonomy_df.index)\n",
    "common_pca_dir = os.path.join(whole_common_taxonomy_dir, \"pca\")\n",
    "\n",
    "Utilities.dump_tsv(whole_common_pca_df.reset_index(), \n",
    "                   os.path.join(common_pca_dir, \"whole_common_pca.tsv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (28, 20)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Principal Component 1\", fontsize = 15)\n",
    "ax.set_ylabel(\"Principal Component 2\", fontsize = 15)\n",
    "ax.set_title(\"2-component PCA\", fontsize = 20)\n",
    "\n",
    "for data_holder in data_holders:\n",
    "    data_holder.export()\n",
    "    pca_x = whole_common_pca_df.loc[data_holder.sample_names, \n",
    "                                    [whole_common_pca_df.columns[0]]].values\n",
    "    pca_y = whole_common_pca_df.loc[data_holder.sample_names, \n",
    "                                    [whole_common_pca_df.columns[1]]].values\n",
    "    ax.scatter(facecolors=data_holder.facecolors, edgecolors=data_holder.edgecolors, \n",
    "               marker=data_holder.marker, label=str(data_holder), x=pca_x, y=pca_y)\n",
    "    for idx, txt in enumerate(data_holder.sample_names):\n",
    "        ax.annotate(txt, (pca_x[idx], pca_y[idx]), fontsize=\"xx-small\")\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(common_pca_dir, \"whole_common_pca.png\"), dpi=300)\n",
    "plt.clf()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "for data_holder in data_holders:\n",
    "    x_col_name = \"volume\"\n",
    "    y_col_name = \"frequency\"\n",
    "    combined_sum_occurrences_df = pd.concat(\n",
    "        [data_holder.sum_df, data_holder.common_taxonomy_counter_df], axis=1, sort=False).rename(\n",
    "        columns={\"sum\": x_col_name, \"occurrences\": y_col_name}).rename_axis(index=\"taxa\").fillna(0)\n",
    "    img_title = \"Regression plot between taxon occurrence {} and {} for {}\".format(\n",
    "        x_col_name, y_col_name, str(data_holder))\n",
    "    Utilities.dump_tsv(combined_sum_occurrences_df, os.path.join(\n",
    "        data_holder.out_dir, \"regressions\", \"{}.tsv\".format(img_title)))\n",
    "    sns.set()\n",
    "    plt.rcParams[\"figure.figsize\"] = (28, 20)\n",
    "    ax = sns.regplot(data=combined_sum_occurrences_df, x=x_col_name, y=y_col_name, fit_reg=False)\n",
    "    _ = ax.set_title(img_title, fontsize = 20)\n",
    "    for ax_line in range(0, len(combined_sum_occurrences_df.index.values)):\n",
    "        ax.text(combined_sum_occurrences_df[x_col_name][ax_line], \n",
    "                combined_sum_occurrences_df[y_col_name][ax_line], \n",
    "                combined_sum_occurrences_df.index.values[ax_line], \n",
    "                fontweight=\"regular\", horizontalalignment=\"left\", color=\"black\", fontsize=3, \n",
    "                rotation=-30, rotation_mode=\"anchor\")\n",
    "    plt.savefig(os.path.join(data_holder.out_dir, \"regressions\", \"{}.png\".format(img_title)), \n",
    "                dpi=300)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "for whole_group_metrics in (\"mean\", \"median\", \"sum\"):\n",
    "    whole_group_correlation_df = pd.concat([getattr(i, \"{}_df\".format(whole_group_metrics)).rename(columns={whole_group_metrics: str(i)}) for i in data_holders], axis=1, sort=False).fillna(0).corr(method=\"spearman\")\n",
    "    pair_correlation_title = \"Whole group correlation for {}\".format(whole_group_metrics)\n",
    "    whole_group_correlation_dir = os.path.join(whole_common_taxonomy_dir, \"correlation\", whole_group_metrics)\n",
    "    Utilities.dump_tsv(whole_group_correlation_df, os.path.join(whole_group_correlation_dir, \"{}.tsv\".format(pair_correlation_title)))\n",
    "    sns.set()\n",
    "    plt.rcParams[\"figure.figsize\"] = (10, 10)   \n",
    "    cg = sns.clustermap(whole_group_correlation_df, metric=\"cityblock\").fig.suptitle(pair_correlation_title, fontsize=10, y=0.995) \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(os.path.join(whole_group_correlation_dir, \"{}.png\".format(pair_correlation_title)), dpi=300)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class DataHolderPair:\n",
    "    \"\"\"\n",
    "    Holds super-group data as DataHolders with the common diagnosis and age values\n",
    "    \"\"\"\n",
    "    def __init__(self, dh1: DataHolder, dh2: DataHolder):\n",
    "        assert dh1 != dh2\n",
    "        self.data_holder_1, self.data_holder_2 = (dh1, dh2)\n",
    "        \n",
    "        self.median_df = pd.concat([i.median_df.rename(\n",
    "            columns={\"median\": str(i)}) for i in list(self)], axis=1, sort=False).rename_axis(\n",
    "            index=\"taxa\", columns=\"medians\")\n",
    "        self.sum_df = pd.concat([i.sum_df.rename(\n",
    "            columns={\"sum\": str(i)}) for i in list(self)], axis=1, sort=False).rename_axis(\n",
    "            index=\"taxa\", columns=\"sums\")\n",
    "\n",
    "        self.pair_taxonomy_ds = pd.concat([i.taxonomy_df for i in list(self)], axis=0, sort=False)\n",
    "        self.pair_names = [str(i) for i in list(self)]\n",
    "        self.pair_common_taxa = sorted(set(self.sum_df.dropna(axis=0).index.values))\n",
    "        self.u_test_df = pd.DataFrame()\n",
    "        for pair_common_taxon in self.pair_common_taxa:\n",
    "            pair_common_2d_array = [\n",
    "                self.pair_taxonomy_ds.loc[i.sample_names, pair_common_taxon].values \n",
    "                for i in list(self)]\n",
    "            self.u_test_df = pd.concat([self.u_test_df, pd.Series(dict(\n",
    "                **get_prevalents_dict(pair_common_2d_array, self.pair_names), \n",
    "                **get_u_test_dict(pair_common_2d_array))).rename(pair_common_taxon)], axis=1, \n",
    "                                       sort=False)\n",
    "        self.u_test_df = self.u_test_df.transpose().rename_axis(index=\"taxa\", columns=\"u-test\")\n",
    "        self.distance_df = pd.concat([pd.Series(\n",
    "            get_distances_dict(i.fillna(0).transpose().values)).rename(j) for i, j in zip(\n",
    "            [self.median_df, self.sum_df], [\"median\", \"sum\"])], axis=1, sort=False)\n",
    "        self.out_dir = os.path.join(output_dir, \"paired\", str(self))\n",
    "\n",
    "    def export(self):\n",
    "        Utilities.dump_tsv(self.median_df.reset_index(), \n",
    "                           os.path.join(self.out_dir, \"raw medians for {}.tsv\".format(str(self))))\n",
    "        Utilities.dump_tsv(self.sum_df.reset_index(), \n",
    "                           os.path.join(self.out_dir, \"raw sums for {}.tsv\".format(str(self))))\n",
    "        Utilities.dump_tsv(self.u_test_df.reset_index(), \n",
    "                           os.path.join(self.out_dir, \"single u-test for {}.tsv\".format(str(self))))\n",
    "\n",
    "    def has_common_property(self, prop: str, value: str):\n",
    "        assert prop in (\"age\", \"diagnosis\", \"sample_source\")\n",
    "        _values = list(set([getattr(i, prop) for i in list(self)]))\n",
    "        return len(_values) == 1 and _values[0] == value\n",
    "\n",
    "    def has_common_props(self, props: dict):\n",
    "        \"\"\"\n",
    "        :param props: dict {prop1: val1, prop2: val2...}\n",
    "        :return: boolean\n",
    "        \"\"\"\n",
    "        return all([self.has_common_property(prop=k, value=props.get(k)) for k in props])\n",
    "\n",
    "    def __eq__(self, other):\n",
    "      return other is not None and sorted(list(self)) == sorted(list(other))\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "    \n",
    "    def __hash__(self):\n",
    "      return hash(str(self))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \" vs \".join(self.pair_names)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"DataHolderPair({})\".format(str(self))\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _dh in (self.data_holder_1, self.data_holder_2):\n",
    "            yield _dh\n",
    "\n",
    "data_holder_pairs = [DataHolderPair(*i) for i in pair_flat_list(data_holders)]\n",
    "data_holder_pairs_grouped_by_sample_source = [{p: v for p, v in zip([\"age\", \"diagnosis\"], j)} \n",
    "                                              for j in product(table_ages, table_diagnoses)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class PatientDataHolder:\n",
    "    \"\"\"\n",
    "    Holds per-patient data\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        raw_ds = table_ds.loc[table_ds[\"patient_ids\"] == self.name]\n",
    "        self.sample_names, sample_sources = [sorted(raw_ds[i].unique()) \n",
    "                                             for i in (\"sample_names\", \"sample_sources\")]\n",
    "        props = (\"patient_diagnoses\", \"patient_ages\")\n",
    "        assert all(len(i) == 2 for i in (self.sample_names, sample_sources)) and all(len(\n",
    "            raw_ds[j].unique()) == 1 for j in props)\n",
    "        self.diagnosis, self.age = raw_ds.loc[:, props].values[0]\n",
    "        self.taxonomy_df = raw_ds.pivot_table(\n",
    "            index=[\"sample_names\", \"sample_sources\"], columns=\"taxa\", \n",
    "            values=\"relative_abundances\").dropna(axis=1, how=\"all\").fillna(0)\n",
    "        distance_dict = get_distances_dict(self.taxonomy_df.values.tolist())\n",
    "        distance_dict.update(dict(sample_names=\" vs \".join(self.sample_names), \n",
    "                                  patient_diagnoses=self.diagnosis, patient_ages=self.age))\n",
    "        self.distance_df = pd.DataFrame(pd.Series(distance_dict).rename(name)).rename_axis(\n",
    "            index=\"metrics\", columns=\"patient_ids\").transpose()\n",
    "        self.common_taxa = get_counter_df(raw_ds[\"taxa\"]).where(\n",
    "            lambda x: x > 1).dropna().index.values\n",
    "        try:\n",
    "            self.blood_to_stool_series = self.taxonomy_df.xs(\n",
    "                \"blood\", level=\"sample_sources\").iloc[0].divide(self.taxonomy_df.xs(\n",
    "                \"stool\", level=\"sample_sources\").iloc[0]).sort_values(ascending=False).rename(name)\n",
    "        except KeyError:\n",
    "            print(self.taxonomy_df)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"[{}, {}, {}]\".format(self.name, self.diagnosis, self.age)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"PatientDataHolder({})\".format(str(self))\n",
    "\n",
    "\n",
    "patient_data_holders = [PatientDataHolder(i) for i in set(table_ds[\"patient_ids\"].values.tolist())]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "distance_metrics = get_distances_dict(list(np.random.randn(2, 10))).keys()\n",
    "whole_distance_metric_df = pd.concat([i.distance_df for i in patient_data_holders], axis=0, \n",
    "                                     sort=False).sort_index()\n",
    "distance_dir = os.path.join(output_dir, \"distances\")\n",
    "\n",
    "Utilities.dump_tsv(whole_distance_metric_df.reset_index(), \n",
    "                   os.path.join(distance_dir, \"whole_distance_metrics.tsv\"))\n",
    "\n",
    "for distance_metric in distance_metrics:\n",
    "    sns.set()\n",
    "    plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "    ax = sns.boxplot(data=whole_distance_metric_df, x=\"patient_ages\", y=distance_metric, \n",
    "                     hue=\"patient_diagnoses\", palette=\"Set3\")\n",
    "    img_title = \"{} between {} samples per patient\".format(\n",
    "        distance_metric, \" and \".join(table_sample_sources))\n",
    "    _ = ax.set_title(img_title, fontsize = 20)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(\"{}.png\".format(os.path.join(distance_dir, img_title)), dpi=300)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "distance_metric_comparison_ds = pd.DataFrame()\n",
    "for distance_metric in distance_metrics:\n",
    "    for age_group in table_ages:\n",
    "        diagnosis_pair_comparison_ds = pd.DataFrame()\n",
    "        for diagnosis_pair in pair_flat_list(table_diagnoses):\n",
    "            diagnosis_pair_dict = dict(distance_metrics=distance_metric, patient_ages=age_group, \n",
    "                                       diagnoses=\" vs \".join(diagnosis_pair))\n",
    "            diagnosis_pair_2d_arr = [whole_distance_metric_df.query(\n",
    "                \"patient_ages == '{}' and patient_diagnoses == '{}'\".format(\n",
    "                    age_group, i))[distance_metric].values for i in diagnosis_pair]\n",
    "            diagnosis_pair_dict.update(get_prevalents_dict(diagnosis_pair_2d_arr, diagnosis_pair))\n",
    "            diagnosis_pair_dict.update(get_u_test_dict(diagnosis_pair_2d_arr))\n",
    "            diagnosis_pair_comparison_ds = pd.concat([diagnosis_pair_comparison_ds, pd.Series(\n",
    "                diagnosis_pair_dict).rename()], axis=1, sort=False)\n",
    "            #\n",
    "        diagnosis_pair_multi_test_df = get_multi_test_df(\n",
    "            diagnosis_pair_comparison_ds.loc[\"p_value\"].values, \n",
    "            diagnosis_pair_comparison_ds.columns)\n",
    "        diagnosis_pair_comparison_ds = pd.concat([diagnosis_pair_comparison_ds.transpose(), \n",
    "                                                  diagnosis_pair_multi_test_df], axis=1, sort=False)\n",
    "        distance_metric_comparison_ds = pd.concat(\n",
    "            [distance_metric_comparison_ds, diagnosis_pair_comparison_ds], axis=0, sort=False, \n",
    "            ignore_index=True)\n",
    "    \n",
    "Utilities.dump_tsv(distance_metric_comparison_ds, os.path.join(\n",
    "    distance_dir, \"distance_metric_comparison_dataset.tsv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "distance_metric_qualifying_df = pd.DataFrame()\n",
    "for distance_metric in distance_metrics:\n",
    "    distance_metric_qualifying_df = pd.concat(\n",
    "        [distance_metric_qualifying_df, distance_metric_comparison_ds.loc[\n",
    "            distance_metric_comparison_ds[\"distance_metrics\"] == distance_metric, [\n",
    "                i for i in distance_metric_comparison_ds.columns if i.startswith(\n",
    "                    \"is_significant_\")]].astype(int).sum().rename(distance_metric)], axis=1, \n",
    "        sort=False)\n",
    " \n",
    "distance_metric_qualifying_df = distance_metric_qualifying_df.transpose()\n",
    "\n",
    "Utilities.dump_tsv(distance_metric_qualifying_df.reset_index(), os.path.join(\n",
    "    distance_dir, \"distance_metric_qualifying_table.tsv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "#!/usr/bin/env python3\n",
     "# -*- coding: utf-8 -*-\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}